rf_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date) %>%
step_rm(arrival_date)
## 5.3 Create Workflow ----
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(rf_recipe)
# 1.0 INTRODUCTION ----
## 1.1 General ----
library(tidymodels)
## 1.2 Helper packages ----
library(readr)       # for importing data
library(vip)         # for variable importance plots
# 2.0 HOTEL BOOKINGS DATA -- STAYS ONLY -- PREDICT CHILDREN ----
## 2.1 Read-in ----
hotels <-
read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
mutate_if(is.character, as.factor)
# 5.4.2 space-filling grid
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(val_set,
grid = 25,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
# 1.0 INTRODUCTION ----
## 1.1 General ----
library(tidymodels)
## 1.2 Helper packages ----
library(readr)       # for importing data
library(vip)         # for variable importance plots
# 2.0 HOTEL BOOKINGS DATA -- STAYS ONLY -- PREDICT CHILDREN ----
## 2.1 Read-in ----
hotels <-
read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%
mutate_if(is.character, as.factor)
## 2.2 View ----
glimpse(hotels)
## 2.3 Outcome variable ----
hotels %>%
count(children) %>%
mutate(prop = n/sum(n))
# 8.3% of reservations
# 3.0 DATA SPLITTING & RESAMPLING ----
## 3.1 Split into stratified random sample----
set.seed(123)
splits      <- initial_split(hotels, strata = children)
hotel_other <- training(splits)
hotel_test  <- testing(splits)
##  3.2 training set proportions by children ----
hotel_other %>%
count(children) %>%
mutate(prop = n/sum(n))
## 3.3 # test set proportions by children ----
hotel_test  %>%
count(children) %>%
mutate(prop = n/sum(n))
## 3.4 validation_split() ----
set.seed(234)
val_set <- validation_split(hotel_other,
strata = children,
prop = 0.80)
# 4.0 FIRST MODEL: PENALIZED LOGISTIC REGRESSION ----
## 4.1 Build the model ----
# tune() as placeholder
# mixture = 1 removes irrelevant predictors
lr_mod <-
logistic_reg(penalty = tune(), mixture = 1) %>%
set_engine("glmnet")
## 4.2 Create recipe ----
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter",
"ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")
lr_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date, holidays = holidays) %>%
step_rm(arrival_date) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
## 4.3 Create workflow
lr_workflow <-
workflow() %>%
add_model(lr_mod) %>%
add_recipe(lr_recipe)
## 4.4 Create grid
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))
lr_reg_grid %>% top_n(-5) # lowest penalty values
lr_reg_grid %>% top_n(5)  # highest penalty values
## 4.5 Train & Tune ----
lr_res <-
lr_workflow %>%
tune_grid(val_set,
grid = lr_reg_grid,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
install.packages("glmnet")
## 4.5 Train & Tune ----
lr_res <-
lr_workflow %>%
tune_grid(val_set,
grid = lr_reg_grid,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
library(glmnet)
install.packages("glmnet")
## 4.5 Train & Tune ----
lr_res <-
lr_workflow %>%
tune_grid(val_set,
grid = lr_reg_grid,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
### 4.5.1 Plot ----
lr_plot <-
lr_res %>%
collect_metrics() %>%
ggplot(aes(x = penalty, y = mean)) +
geom_point() +
geom_line() +
ylab("Area under the ROC Curve") +
scale_x_log10(labels = scales::label_number())
lr_plot
# 5.0 SECOND MODEL: TREE-BASED ENSEMBLE ----
# An effective and low-maintenance modeling technique is a random forest.
# Tree-based models require very little preprocessing and can handle many types
# of predictors (sparse, skewed, continuous, categorical, etc.).
## 5.1 Build model reduce training time ----
# The tune package can do parallel processing for you, and allows users
# to use multiple cores or separate machines to fit models.
### 5.1.1 Detect cores ----
cores <- parallel::detectCores()
cores
### 5.1.2 Build model ----
rf_mod <-
rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
# tune() is placeholder for later
set_engine("ranger", num.threads = cores) %>%
set_mode("classification")
### 5.1.3 CAUTION: Don't set cores except for random forest ----
## 5.2 Create Recipe ----
#Unlike penalized logistic regression models, random forest models do
#not require dummy or normalized predictor variables.
rf_recipe <-
recipe(children ~ ., data = hotel_other) %>%
step_date(arrival_date) %>%
step_holiday(arrival_date) %>%
step_rm(arrival_date)
## 5.3 Create Workflow ----
rf_workflow <-
workflow() %>%
add_model(rf_mod) %>%
add_recipe(rf_recipe)
## 5.4 Train and Tune Model ----
### 5.4.1 Show what will be tuned
rf_mod %>%
parameters()
### 5.4.2 space-filling grid ----
set.seed(345)
rf_res <-
rf_workflow %>%
tune_grid(val_set,
grid = 25,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc))
### 5.4.3 Show the best ----
rf_res %>%
show_best(metric = "roc_auc")
### 5.4.4 Plot
#However, the range of the y-axis indicates that the model is
#very robust to the choice of these parameter values — all but
#one of the ROC AUC values are greater than 0.90.
autoplot(rf_res)
### 5.4.5 Select best ----
rf_best <-
rf_res %>%
select_best(metric = "roc_auc")
rf_best
### 5.4.6 Filter model to best prediction ----
rf_auc <-
rf_res %>%
collect_predictions(parameters = rf_best) %>%
roc_curve(children, .pred_children) %>%
mutate(model = "Random Forest")
### 5.4.7 Plot best model ----
bind_rows(rf_auc, lr_auc) %>%
ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +
geom_path(lwd = 1.5, alpha = 0.8) +
geom_abline(lty = 3) +
coord_equal() +
scale_color_viridis_d(option = "plasma", end = .6)
# error lr_auc was in previous lesson
# 6.0 THE LAST FIT ----
#build parsnip model object again from scratch
#take our best hyperparameter values from our random forest model.
# set new argument: importance = "impurity"
## 6.1  last model ----
last_rf_mod <-
rand_forest(mtry = 8, min_n = 7, trees = 1000) %>%
set_engine("ranger", num.threads = cores, importance = "impurity") %>%
set_mode("classification")
## 6.2 last workflow ----
last_rf_workflow <-
rf_workflow %>%
update_model(last_rf_mod)
## 6.3 last fit ----
set.seed(345)
last_rf_fit <-
last_rf_workflow %>%
last_fit(splits)
## 6.4 evaluate model ----
last_rf_fit %>%
collect_metrics()
## 6.5 review variable importance ----
last_rf_fit %>%
pluck(".workflow", 1) %>%
pull_workflow_fit() %>%
vip(num_features = 20)
## 6.6 last roc ----
#similar to validation set.  good predictor on new data.
last_rf_fit %>%
collect_predictions() %>%
roc_curve(children, .pred_children) %>%
autoplot()
banner('tinymodels', '1 build a model', 'url: https://www.tidymodels.org/start/models/')
#################################################################
##                          tinymodels                         ##
##                       1 build a model                       ##
##        url: https://www.tidymodels.org/start/models/        ##
#################################################################
# 1.0 INTRODUCTION ----
## 1.1 Parsnip pkg + the rest of tidymodels ----
library(tidymodels)
## 1.2 Helper packages ----
library(readr)       # for importing data
library(broom.mixed) # for converting bayesian models to tidy tibbles
library(dotwhisker)  # for visualizing regression results
# 2.0 SEA URCHINS DATA ----
## 2.1 About ----
# https://link.springer.com/article/10.1007/BF00349318
## 2.2 Read-in ----
urchins <-
# Data were assembled for a tutorial
# at https://www.flutterbys.com.au/stats/tut/tut7.5a.html
read_csv("https://tidymodels.org/start/models/urchins.csv") %>%
# Change the names to be a little more verbose
setNames(c("food_regime", "initial_volume", "width")) %>%
# Factors are very helpful for modeling, so we convert one column
mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))
## 2.3 Plot ----
ggplot(urchins,
aes(x = initial_volume,
y = width,
group = food_regime,
col = food_regime)) +
geom_point() +
geom_smooth(method = lm, se = FALSE) +
scale_color_viridis_d(option = "plasma", end = .7)
# 3.0 BUILD AND FIT A MODEL ----
#A standard two-way analysis of variance (ANOVA) model makes sense for this
#dataset because it contains a continuous and categorical predictor
## 3.1 Designate model ----
lm_mod <-
linear_reg() %>%
set_engine("lm")
## 3.2 Train/fit/estimate model ----
lm_fit <-
lm_mod %>%
fit(width ~ initial_volume * food_regime, data = urchins)
## 3.3 print tidy ----
tidy(lm_fit)
## 3.4 plot results ----
tidy(lm_fit) %>%
dwplot(dot_args = list(size = 2, color = "black"),
whisker_args = list(color = "black"),
vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
# 4.0 USE A MODEL TO PREDICT ----
## 4.1 Create new points ----
new_points <- expand.grid(initial_volume = 20,
food_regime = c("Initial", "Low", "High"))
## 4.2 Fit model to new data points ----
mean_pred <- predict(lm_fit, new_data = new_points)
## 4.3 Create confidence intervals for predictions ----
conf_int_pred <- predict(lm_fit,
new_data = new_points,
type = "conf_int")
## 4.4 New data: new points + estimates + conf int ----
plot_data <-
new_points %>%
bind_cols(mean_pred) %>%
bind_cols(conf_int_pred)
## 4.5 And then plot . . . ----
ggplot(plot_data, aes(x = food_regime)) +
geom_point(aes(y = .pred)) +
geom_errorbar(aes(ymin = .pred_lower,
ymax = .pred_upper),
width = .2) +
labs(y = "urchin size")
# 5.0 MODEL WITH A DIFFERENT ENGINE ----
## 5.1 Set the prior distribution ----
prior_dist <- rstanarm::student_t(df = 1)
install.packages("rstanarm")
devtools::install_github(“stan-dev/rstanarm”, build_vignettes = TRUE)
devtools::install_github(“stan-dev/rstanarm”, build_vignettes = FALSE)
install_github("stan-dev/rstanarm")
install.packages("rstan")
install.packages("rstanarm")
install.packages("rstanarm")
install.packages("remotes")
# Change 2 to however many cores you can/want to use to parallelize install
# If you experience crashes or run out RAM during installation, try changing this to 1
Sys.setenv(MAKEFLAGS = "-j2")
Sys.setenv("R_REMOTES_NO_ERRORS_FROM_WARNINGS" = "true")
remotes::install_github("stan-dev/rstanarm", INSTALL_opts = "--no-multiarch", force = TRUE)
banner("tidy models", "2 Preprocess with Recipes", 'url: https://www.tidymodels.org/start/recipes/')
banner('tidymodels', '3 Evaluate Model with Resampling', 'url: https://www.tidymodels.org/start/resampling/')
# 1.0 INTRODUCTION ----
#Resampling measures how well a model predicts new data
#predict image segmentation quality
## 1.1 Load tidymodels ----
library(tidymodels) # for the resample package, along with the rest of tidymodels
# 1.0 INTRODUCTION ----
#Resampling measures how well a model predicts new data
#predict image segmentation quality
## 1.1 Load tidymodels ----
library(tidymodels) # for the resample package, along with the rest of tidymodels
## 1.2 Load helper packages -----
library(modeldata)  # for the cells data
# 2.0 THE CELL IMAGE DATA ----
## 2.1 Load data ----
data(cells, package = "modeldata")
## 2.2 Outcome variable
# PS = "poorly segmented" WS = "weekly segmented"
cells %>%
count(class) %>%
mutate(prop = n/sum(n))
library(resample)
install.packages("tidymodels")
library(resample)
# DATA SPLITTING
#The function rsample::initial_split() takes the original data and saves
#the information on how to make the partitions. In the original analysis,
#the authors made their own training/test set and that information is
#contained in the column "case". To demonstrate how to make a split, we’ll
#remove this column before we make our own split:
set.seed(123)
cell_split <- rsample::initial_split(cells %>% select(-case),
strata = class)
library(magrittr)
# DATA SPLITTING
#The function rsample::initial_split() takes the original data and saves
#the information on how to make the partitions. In the original analysis,
#the authors made their own training/test set and that information is
#contained in the column "case". To demonstrate how to make a split, we’ll
#remove this column before we make our own split:
set.seed(123)
cell_split <- rsample::initial_split(cells %>% select(-case),
strata = class)
library(tidyverse)
# DATA SPLITTING
#The function rsample::initial_split() takes the original data and saves
#the information on how to make the partitions. In the original analysis,
#the authors made their own training/test set and that information is
#contained in the column "case". To demonstrate how to make a split, we’ll
#remove this column before we make our own split:
set.seed(123)
cell_split <- rsample::initial_split(cells %>% select(-case),
strata = class)
#Here we used the strata argument, which conducts a stratified split. This
#ensures that, despite the imbalance we noticed in our class variable, our
#training and test data sets will keep roughly the same proportions of poorly #
#and well-segmented cells as in the original data. After the initial_split,
#the training() and testing() functions return the actual data sets.
cell_train <- training(cell_split)
# 1.0 INTRODUCTION ----
#Resampling measures how well a model predicts new data
#predict image segmentation quality
## 1.1 Load tidymodels ----
library(tidymodels) # for the resample package, along with the rest of tidymodels
## 1.2 Load helper packages -----
library(modeldata)  # for the cells data
# 2.0 THE CELL IMAGE DATA ----
## 2.1 Load data ----
data(cells, package = "modeldata")
## 2.2 Outcome variable is 'class'
# PS = "poorly segmented" WS = "weekly segmented"
cells %>%
count(class) %>%
mutate(prop = n/sum(n))
# DATA SPLITTING
#The function rsample::initial_split() takes the original data and saves
#the information on how to make the partitions. In the original analysis,
#the authors made their own training/test set and that information is
#contained in the column "case". To demonstrate how to make a split, we’ll
#remove this column before we make our own split:
set.seed(123)
cell_split <- rsample::initial_split(cells %>% select(-case),
strata = class)
#Here we used the strata argument, which conducts a stratified split. This
#ensures that, despite the imbalance we noticed in our class variable, our
#training and test data sets will keep roughly the same proportions of poorly #
#and well-segmented cells as in the original data. After the initial_split,
#the training() and testing() functions return the actual data sets.
cell_train <- training(cell_split)
cell_test  <- testing(cell_split)
# CREATE MODEL
#One of the benefits of a random forest model is that it is very low maintenance;
#it requires very little preprocessing of the data and the default parameters
#tend to give reasonable results. For that reason, we won’t create a recipe for
#the cells data.
rf_mod <-
rand_forest(trees = 1000) %>%
set_engine("ranger") %>%
set_mode("classification")
# FIT MODEL
# This new rf_fit object is our fitted model, trained on our training data set
set.seed(234)
rf_fit <-
rf_mod %>%
fit(class ~ ., data = cell_train)
# FIT A MODEL WITH RESAMPLING
set.seed(345)
folds <- vfold_cv(cell_train, v = 10)
folds
rf_wf <-
workflow() %>%
add_model(rf_mod) %>%
add_formula(class ~ .)
set.seed(456)
rf_fit_rs <-
rf_wf %>%
fit_resamples(folds)
collect_metrics(rf_fit_rs)
# 1.0 INTRODUCTION ----
#Resampling measures how well a model predicts new data
#predict image segmentation quality
## 1.1 Load tidymodels ----
library(tidymodels) # for the resample package, along with the rest of tidymodels
## 1.2 Load helper packages -----
library(modeldata)  # for the cells data
# 2.0 THE CELL IMAGE DATA ----
## 2.1 Load data ----
data(cells, package = "modeldata")
## 2.2 Outcome variable is 'class'
# PS = "poorly segmented" WS = "weekly segmented"
cells %>%
count(class) %>%
mutate(prop = n/sum(n))
# 3.0 DATA SPLITTING ----
#The function rsample::initial_split() takes the original data and saves
#the information on how to make the partitions. In the original analysis,
#the authors made their own training/test set and that information is
#contained in the column "case". To demonstrate how to make a split, we’ll
#remove this column before we make our own split:
set.seed(123)
cell_split <- rsample::initial_split(cells %>% select(-case),
strata = class)
#Here we used the strata argument, which conducts a stratified split. This
#ensures that, despite the imbalance we noticed in our class variable, our
#training and test data sets will keep roughly the same proportions of poorly #
#and well-segmented cells as in the original data. After the initial_split,
#the training() and testing() functions return the actual data sets.
cell_train <- training(cell_split)
cell_test  <- testing(cell_split)
# 4.0 CREATE MODEL
#One of the benefits of a random forest model is that it is very low maintenance;
#it requires very little preprocessing of the data and the default parameters
#tend to give reasonable results. For that reason, we won’t create a recipe for
#the cells data.
rf_mod <-
rand_forest(trees = 1000) %>%
set_engine("ranger") %>%
set_mode("classification")
# 4.0 MODELING ----
# This new rf_fit object is the fitted model, trained on the training data set
set.seed(234)
rf_fit <-
rf_mod %>%
fit(class ~ ., data = cell_train)
# 6.0 FIT A MODEL WITH RESAMPLING ----
## 6.1 Fit model ----
set.seed(345)
folds <- vfold_cv(cell_train, v = 10)
folds
rf_wf <-
workflow() %>%
add_model(rf_mod) %>%
add_formula(class ~ .)
set.seed(456)
rf_fit_rs <-
rf_wf %>%
fit_resamples(folds)
## 6.2 Collect metrics ----
collect_metrics(rf_fit_rs)
#Think about these values we now have for accuracy and AUC. These performance
#metrics are now more realistic (i.e. lower) than our ill-advised first attempt
#at computing performance metrics in the section above.
rf_testing_pred <-                      # original bad idea
predict(rf_fit, cell_test) %>%
bind_cols(predict(rf_fit, cell_test, type = "prob")) %>%
bind_cols(cell_test %>% select(class))
rf_testing_pred %>%                   # test set predictions
roc_auc(truth = class, .pred_PS)
rf_testing_pred %>%                   # test set predictions
accuracy(truth = class, .pred_class)
setwd("../blogdown-default")
blogdown:::new_post_addin()
blogdown::serve_site()
